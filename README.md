# Author Identification in Academic Publishing
This project delves into the implications of advanced Natural Language Processing (NLP) techniques on preserving anonymity in academic paper reviews by successfully classifying anonymous text with an accuracy exceeding 75%. This has been accomplished using Machine Learning (ML) models trained on a comprehensive publication database encompassing 17 authors.

## Objective and Context
The overarching objective of this research is to underscore the potential vulnerabilities introduced by NLP advancements on the preservation of anonymity during the journal review process. An integral aspect of the academic review mechanism is the anonymity of the reviewers, which instills a sense of confidence in scholars, enabling them to provide forthright and unbiased feedback on submissions. However, this initiative unveils the alarming possibility of attributing anonymous review excerpts to their respective authors, by training predictive models on their previous publications.

## Outcomes
The outcome  of this project is an interactive histogram, facilitating users to seamlessly transition between different predictive models and adjust sensitivity parameters. This versatility aids in gauging the proficiency of each model in predicting the authorship of an anonymous text sample.

![Author_Predictions](https://github.com/Howard-nolan/Author-Classifier-Project/assets/106356427/d3b1927f-787f-43eb-83ec-f22b5646f6dd)

## Data Collection
The employed dataset consists of between 5 to 10 academic papers from a pool of 17 authors, all of whom specialize in experimental economics. Notably, the dataset marks papers co-authored by multiple economists featured within this collection. Users have the flexibility to either include or exclude these co-authored papers during model training, based on their analytical preferences.
